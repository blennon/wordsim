{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "from scipy import sparse\n",
      "from sklearn.decomposition import TruncatedSVD"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_wordlist(fname='/usr/share/dict/words'):\n",
      "    return [l.strip() for l in open(fname).readlines()]\n",
      "\n",
      "def extract_ngrams_from(word, n):\n",
      "    return [word[i:i+n] for i in range(len(word) - n+1)]\n",
      "\n",
      "def unique_ngrams(words, n):\n",
      "    ngrams = set()\n",
      "    for w in words:\n",
      "        ngrams.update(extract_ngrams_from(w, n))\n",
      "    return list(ngrams)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordlist = [w.lower() for w in read_wordlist()]\n",
      "ngrams_list = unique_ngrams(wordlist, 3)\n",
      "print 'summary statistics'\n",
      "print 'n number percent'\n",
      "for i in range(5):\n",
      "    n = len(unique_ngrams(wordlist, i+1))\n",
      "    print i+1, n, float(n)/(44**i+1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "summary statistics\n",
        "n number percent\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 44 22.0\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 724 16.0888888889\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7308 3.77284460506\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35241 0.413699594999\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 76972 0.0205362881484\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def co_occur(ngrams,d):\n",
      "    occurs = Counter()\n",
      "    for i in range(len(ngrams)):\n",
      "        for j in range(1,d+1):\n",
      "            if i+j < len(ngrams):\n",
      "                occurs[(ngrams[i],ngrams[i+j])] += 1*(1./j)\n",
      "            if i-j>0:\n",
      "                occurs[(ngrams[i],ngrams[i-j])] += 1*(1./j)\n",
      "    return occurs\n",
      "\n",
      "def reduce_occurs(co_occurs):\n",
      "    reduced_occurs = []\n",
      "    last, val = co_occurs[0][0], 0\n",
      "    for co in co_occurs:\n",
      "        if co[0] == last:\n",
      "            val += co[1]\n",
      "        else:\n",
      "            reduced_occurs.append((last,val))\n",
      "            last, val = co[0], co[1]\n",
      "    reduced_occurs.append((last,val))\n",
      "    return reduced_occurs\n",
      "\n",
      "def occurs_to_matrix(occurs,ngrams):\n",
      "    mat = zeros((len(ngrams),len(ngrams)))\n",
      "    for ng_pair, count in occurs:\n",
      "        ind1, ind2 = ngrams.index(ng_pair[0]), ngrams.index(ng_pair[1])\n",
      "        mat[ind1,ind2] += count\n",
      "    return mat\n",
      "\n",
      "def count_occurs(wordlist, ngrams_list, n, dist):\n",
      "    '''\n",
      "    returns a co_occurrence matrix\n",
      "    '''\n",
      "    co_occurs = []\n",
      "    for w in wordlist:\n",
      "        ngrams = extract_ngrams_from(w, n)\n",
      "        co_occurs+=co_occur(ngrams,dist).items()   \n",
      "    reduced_occurs = reduce_occurs(sorted(co_occurs))\n",
      "    return occurs_to_matrix(reduced_occurs, ngrams_list)\n",
      "\n",
      "def normalize_by_row(mat):\n",
      "    '''\n",
      "    normalize rows in the matrix by the row sum\n",
      "    '''\n",
      "    norm = sparse.spdiags(1./(.0001+mat.sum(1).T), 0, *mat.shape)\n",
      "    return norm * mat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "occurs = normalize_by_row(count_occurs(wordlist, ngrams_list, 3, 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ContextVectorSpace(object):\n",
      "    '''\n",
      "    A context vector space consists of a list of elements, 'elements',\n",
      "    and corresponding array of context vectors, 'CVs', arranged as\n",
      "    (num_elements, vec_space_dimension)\n",
      "    '''\n",
      "    \n",
      "    def __init__(self, CVs, elements):\n",
      "        self.CVs = CVs\n",
      "        self.elements = elements\n",
      "    \n",
      "    def compare_elements(self, e1, e2):\n",
      "        return self.compare_cvs(self.get_cv(e1), self.get_cv(e2))\n",
      "    \n",
      "    def get_nearest_elements(self, element, n):\n",
      "        cvs = self.get_nearest_cvs(self.get_cv(element), n)\n",
      "        return [(self.get_element(cv[1]),cv[0]) for cv in cvs]\n",
      "    \n",
      "    def get_nearest_cvs(self, cv, n):\n",
      "        return sorted(zip(dot(self.CVs,cv),arange(self.CVs.shape[0])),reverse=True)[:n]\n",
      "        \n",
      "    def compare_cvs(self, cv1, cv2):\n",
      "        return dot(cv1, cv2)\n",
      "    \n",
      "    def get_cv(self, element):\n",
      "        return self.CVs[self.get_index(element),:]\n",
      "    \n",
      "    def get_index(self, element):\n",
      "        return self.elements.index(element)\n",
      "    \n",
      "    def get_element(self, index):\n",
      "        return self.elements[index]\n",
      "    \n",
      "    @staticmethod\n",
      "    def normalize_vector(vec):\n",
      "        return vec/norm(vec, ord=2)\n",
      "    \n",
      "    @staticmethod\n",
      "    def normalize_matrix(mat):\n",
      "        '''\n",
      "        Normalizes (L2) the rows of the matrix to be unit length\n",
      "        '''\n",
      "        norm = (mat**2).sum(1)**.5\n",
      "        norm[norm==0.] = 1\n",
      "        return mat/norm[...,None]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NgramSpace(ContextVectorSpace):\n",
      "    \n",
      "    def __init__(self, occurs, dim, ngrams, N):\n",
      "        self.dim = dim\n",
      "        self.elements = ngrams\n",
      "        self.N = N\n",
      "        self.SVD = TruncatedSVD(n_components=dim)\n",
      "        self.CVs = ContextVectorSpace.normalize_matrix(self.SVD.fit_transform(occurs))    \n",
      "    \n",
      "    def build_word_cv(self, word):\n",
      "        cv = zeros(self.dim)\n",
      "        ngrams = extract_ngrams_from(word, self.N)\n",
      "        for ng in ngrams:\n",
      "            cv = cv + self.get_cv(ng)\n",
      "        return ContextVectorSpace.normalize_vector(cv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class WordSpace(ContextVectorSpace):\n",
      "    \n",
      "    def __init__(self, wordlist, NgramSpace):\n",
      "        self.elements = wordlist\n",
      "        self.NgramSpace = NgramSpace\n",
      "        self.CVs = self.build_word_cvs()\n",
      "    \n",
      "    def get_nearest_elements(self, element, n):\n",
      "        try:\n",
      "            cv = self.get_cv(element)\n",
      "        except:\n",
      "            cv = self.NgramSpace.build_word_cv(element)\n",
      "        cvs = self.get_nearest_cvs(cv, n)\n",
      "        return [(self.get_element(cv[1]),cv[0]) for cv in cvs]\n",
      "    \n",
      "    def build_word_cvs(self):\n",
      "        CVs = zeros((len(self.elements),self.NgramSpace.CVs.shape[1]))\n",
      "        for i, word in enumerate(self.elements):\n",
      "            CVs[i,:] = self.NgramSpace.build_word_cv(word)\n",
      "        return CVs            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NgramCV = NgramSpace(occurs, 100, ngrams_list, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "WordCV = WordSpace([w for w in wordlist if len(w)>3], NgramCV)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NgramCV.compare_elements('tru','rus')\n",
      "NgramCV.get_nearest_elements('rin', 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "[('rin', 0.99999999999999911),\n",
        " ('pin', 0.99854548658242814),\n",
        " ('sin', 0.99844494246609239),\n",
        " ('nin', 0.99842597902872576),\n",
        " ('ein', 0.99840484716057953),\n",
        " ('cin', 0.99829752544605044),\n",
        " ('gin', 0.9982140289549003),\n",
        " ('din', 0.99820289105813731),\n",
        " ('hin', 0.99818784697657525),\n",
        " ('fin', 0.9979691714097414)]"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print WordCV.compare_elements('trust','thrust')\n",
      "WordCV.get_nearest_elements('cart',25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.913373799592\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "[('cart', 0.99999999999999978),\n",
        " ('bart', 0.99747864093776817),\n",
        " ('hart', 0.99687933319993105),\n",
        " ('hart', 0.99687933319993105),\n",
        " ('dart', 0.99673288724655351),\n",
        " ('wart', 0.99390875161224668),\n",
        " ('tart', 0.96904536103958527),\n",
        " ('part', 0.96564637603233761),\n",
        " ('hardhearted', 0.95650897359740794),\n",
        " ('hardheartedly', 0.94042705444478236),\n",
        " ('earhart', 0.93968756390242736),\n",
        " ('fart', 0.9342200928763893),\n",
        " ('warmhearted', 0.93353428921048032),\n",
        " ('tartars', 0.92530899578651737),\n",
        " ('tartars', 0.92530899578651737),\n",
        " ('earnhardt', 0.92096217234052669),\n",
        " ('harte', 0.92051816929489105),\n",
        " ('tare', 0.91814978938736469),\n",
        " ('bare', 0.91575459335417042),\n",
        " ('bars', 0.91368660593385997),\n",
        " ('dare', 0.91333306360815114),\n",
        " ('dare', 0.91333306360815114),\n",
        " ('heart', 0.91320855799848211),\n",
        " ('hare', 0.91293984722930821),\n",
        " ('care', 0.9096261749417518)]"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}